{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **SALES PREDICTION** ","metadata":{"_uuid":"eb75d57ef5c0c094eb265c3fb4ef77b8f8c73dce"}},{"cell_type":"markdown","source":"### **Problem Statement**\n\nBuild a model which predicts sales based on the money spent on different platforms for marketing.\n\n### Data\nUse the advertising dataset given in ISLR and analyse the relationship between 'TV advertising' and 'sales' using a simple linear regression model. \n\nIn this notebook, we'll build a **LinearRegression model, DecisionTreeResgression Model and RandomForestRegression Model** to predict `Sales` using an appropriate predictor variable.","metadata":{}},{"cell_type":"markdown","source":"## Reading and Understanding the Data","metadata":{"_uuid":"fab1024005bc13658e3ef2f8a2e46971881bc3ef"}},{"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import the numpy and pandas package\n\nimport numpy as np\nimport pandas as pd\n\n# Data Visualisation\nimport matplotlib.pyplot as plt \nimport seaborn as sns","metadata":{"_uuid":"d68008018678c65564ddda5994cb05129f3ca72b","execution":{"iopub.status.busy":"2023-08-29T16:30:58.868694Z","iopub.execute_input":"2023-08-29T16:30:58.869071Z","iopub.status.idle":"2023-08-29T16:30:58.875046Z","shell.execute_reply.started":"2023-08-29T16:30:58.869026Z","shell.execute_reply":"2023-08-29T16:30:58.873735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **DATA LOADING**\n\nThe dataset contain the advertising dataset.","metadata":{}},{"cell_type":"code","source":"advertising = pd.DataFrame(pd.read_csv(\"../input/advertising.csv\"))\nadvertising.head()","metadata":{"_uuid":"1365d38deb407ea9c0f4e93830c5f9d4d65ebd9d","execution":{"iopub.status.busy":"2023-08-29T16:30:58.882606Z","iopub.execute_input":"2023-08-29T16:30:58.882934Z","iopub.status.idle":"2023-08-29T16:30:58.926339Z","shell.execute_reply.started":"2023-08-29T16:30:58.882881Z","shell.execute_reply":"2023-08-29T16:30:58.925287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis (EDA)**\nEDA stands for Exploratory Data Analysis. It is a critical step in the data analysis process that involves examining and visualizing data sets to understand their main characteristics, patterns, and relationships. The primary goal of EDA is to gain insights, detect anomalies, and inform the data modeling process.","metadata":{"_uuid":"39753c6695c9c1fb90e9d0bbbba0bf8c09b600c2"}},{"cell_type":"markdown","source":"# **1. Summarize Data:**\n\nThis involves calculating descriptive statistics such as **mean, median, mode, standard deviation,** and other relevant measures to understand the central tendency and spread of the data.","metadata":{}},{"cell_type":"code","source":"advertising.shape","metadata":{"scrolled":true,"_uuid":"4f36948806d235d179b1a5c6b6c990a41afc6e4a","execution":{"iopub.status.busy":"2023-08-29T16:30:58.927781Z","iopub.execute_input":"2023-08-29T16:30:58.928064Z","iopub.status.idle":"2023-08-29T16:30:58.933763Z","shell.execute_reply.started":"2023-08-29T16:30:58.928009Z","shell.execute_reply":"2023-08-29T16:30:58.932769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advertising.columns   #total 4 columns ['TV', 'Radio', 'Newspaper', 'Sales']","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:30:58.935098Z","iopub.execute_input":"2023-08-29T16:30:58.935407Z","iopub.status.idle":"2023-08-29T16:30:58.949560Z","shell.execute_reply.started":"2023-08-29T16:30:58.935330Z","shell.execute_reply":"2023-08-29T16:30:58.948660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advertising.info()   #4 features are the numerical datatype .","metadata":{"_uuid":"9578033b7d507aa4d901b48de36931066cc00241","execution":{"iopub.status.busy":"2023-08-29T16:30:58.950875Z","iopub.execute_input":"2023-08-29T16:30:58.951177Z","iopub.status.idle":"2023-08-29T16:30:58.965279Z","shell.execute_reply.started":"2023-08-29T16:30:58.951111Z","shell.execute_reply":"2023-08-29T16:30:58.964534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advertising.describe()","metadata":{"_uuid":"b817b9601c376627448453b03d79bf8f9dd02eac","execution":{"iopub.status.busy":"2023-08-29T16:30:58.966651Z","iopub.execute_input":"2023-08-29T16:30:58.966948Z","iopub.status.idle":"2023-08-29T16:30:59.008887Z","shell.execute_reply.started":"2023-08-29T16:30:58.966896Z","shell.execute_reply":"2023-08-29T16:30:59.007910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2. Visualisation and Insights**","metadata":{"_uuid":"fab7463f8ed5eb55f1357db16c69204351295edf"}},{"cell_type":"code","source":"# Checking Null values\nadvertising.isnull().sum()*100/advertising.shape[0]\n# There are no NULL values in the dataset, hence it is clean.","metadata":{"_uuid":"cf9580e58b78c0558d96f54272701b6d2d32a018","execution":{"iopub.status.busy":"2023-08-29T16:30:59.010615Z","iopub.execute_input":"2023-08-29T16:30:59.010918Z","iopub.status.idle":"2023-08-29T16:30:59.020057Z","shell.execute_reply.started":"2023-08-29T16:30:59.010858Z","shell.execute_reply":"2023-08-29T16:30:59.018903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Outlier Analysis\nfig, axs = plt.subplots(3, figsize = (5,5))\nplt1 = sns.boxplot(advertising['TV'], ax = axs[0])\nplt2 = sns.boxplot(advertising['Newspaper'], ax = axs[1])\nplt3 = sns.boxplot(advertising['Radio'], ax = axs[2])\nplt.tight_layout()","metadata":{"_uuid":"c427a8e8a84e617eccdeda7df5eccd25f740f25d","execution":{"iopub.status.busy":"2023-08-29T16:30:59.021474Z","iopub.execute_input":"2023-08-29T16:30:59.021741Z","iopub.status.idle":"2023-08-29T16:30:59.636356Z","shell.execute_reply.started":"2023-08-29T16:30:59.021697Z","shell.execute_reply":"2023-08-29T16:30:59.634857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are no considerable outliers present in the data.","metadata":{"_uuid":"3f18bb0cc6014b12746f45ea30a7b769a59ad1a4","execution":{"iopub.status.busy":"2023-08-29T16:30:59.638609Z","iopub.execute_input":"2023-08-29T16:30:59.639405Z","iopub.status.idle":"2023-08-29T16:30:59.645606Z","shell.execute_reply.started":"2023-08-29T16:30:59.639293Z","shell.execute_reply":"2023-08-29T16:30:59.643996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Sales (Target Variable)","metadata":{"_uuid":"7ebb232846d9ae796b258eb26642ef73ca2dcacc"}},{"cell_type":"code","source":"sns.boxplot(advertising['Sales'])\nplt.show()","metadata":{"_uuid":"d435bd318677f7a4234bf02efdf54aa19e8b2c16","execution":{"iopub.status.busy":"2023-08-29T16:30:59.647683Z","iopub.execute_input":"2023-08-29T16:30:59.648624Z","iopub.status.idle":"2023-08-29T16:30:59.861601Z","shell.execute_reply.started":"2023-08-29T16:30:59.648530Z","shell.execute_reply":"2023-08-29T16:30:59.859411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see how Sales are related with other variables using scatter plot.\nsns.pairplot(advertising, x_vars=['TV', 'Newspaper', 'Radio'], y_vars='Sales', height=4, aspect=1, kind='scatter')\nplt.show()","metadata":{"_uuid":"2d6f716ebe182a58f9941c059256a09cc7f03703","execution":{"iopub.status.busy":"2023-08-29T16:30:59.864083Z","iopub.execute_input":"2023-08-29T16:30:59.865128Z","iopub.status.idle":"2023-08-29T16:31:00.678405Z","shell.execute_reply.started":"2023-08-29T16:30:59.865028Z","shell.execute_reply":"2023-08-29T16:31:00.677066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see the correlation between different variables.\nsns.heatmap(advertising.corr(), cmap=\"YlGnBu\", annot = True)\nplt.show()","metadata":{"_uuid":"ea27ea99e47d578866a706f437d74a8fe1ad2264","execution":{"iopub.status.busy":"2023-08-29T16:31:00.680465Z","iopub.execute_input":"2023-08-29T16:31:00.680974Z","iopub.status.idle":"2023-08-29T16:31:01.141944Z","shell.execute_reply.started":"2023-08-29T16:31:00.680928Z","shell.execute_reply":"2023-08-29T16:31:01.140563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As is visible from the pairplot and the heatmap, the variable `TV` seems to be most correlated with `Sales`. So let's go ahead and perform simple linear regression using `TV` as our feature variable.","metadata":{"_uuid":"de3f5b90d0b6165958efcf1a31b80141867987fe"}},{"cell_type":"markdown","source":"# **Splitting**  the Data set into Train and Test","metadata":{}},{"cell_type":"code","source":"X = advertising[['TV','Radio','Newspaper']]\ny = advertising['Sales']","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:31:01.144090Z","iopub.execute_input":"2023-08-29T16:31:01.144892Z","iopub.status.idle":"2023-08-29T16:31:01.153629Z","shell.execute_reply.started":"2023-08-29T16:31:01.144807Z","shell.execute_reply":"2023-08-29T16:31:01.152367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You now need to split our variable into training and testing sets. You'll perform this by importing `train_test_split` from the `sklearn.model_selection` library. It is usually a good practice to keep 70% of the data in your train dataset and the rest 30% in your test dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state = 100)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:31:01.155626Z","iopub.execute_input":"2023-08-29T16:31:01.156366Z","iopub.status.idle":"2023-08-29T16:31:01.172034Z","shell.execute_reply.started":"2023-08-29T16:31:01.156285Z","shell.execute_reply":"2023-08-29T16:31:01.170618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's now take a look at the train dataset\n\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:31:01.174588Z","iopub.execute_input":"2023-08-29T16:31:01.175417Z","iopub.status.idle":"2023-08-29T16:31:01.210658Z","shell.execute_reply.started":"2023-08-29T16:31:01.175318Z","shell.execute_reply":"2023-08-29T16:31:01.209918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:31:01.211651Z","iopub.execute_input":"2023-08-29T16:31:01.212018Z","iopub.status.idle":"2023-08-29T16:31:01.219004Z","shell.execute_reply.started":"2023-08-29T16:31:01.211977Z","shell.execute_reply":"2023-08-29T16:31:01.217878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train the model:**\n\nHyper Parameter tuning :Hyperparameter tuning, also known as hyperparameter optimization, is the process of finding the best set of hyperparameters for a machine learning model to achieve optimal performance on a given dataset\n\nThere are two main hyperparameter tuning techniques:\n\nGridSearchCV\nRandomizedSearchCV\n\n# **1.Linear Regression Model**\n\n","metadata":{"_uuid":"6d593021918853ea7402f5efa6348425481dd538"}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:31:01.220078Z","iopub.execute_input":"2023-08-29T16:31:01.220523Z","iopub.status.idle":"2023-08-29T16:31:01.234293Z","shell.execute_reply.started":"2023-08-29T16:31:01.220478Z","shell.execute_reply":"2023-08-29T16:31:01.233200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a Linear Regression model\nbaseline_model = LinearRegression()\n\n# Hyperparameter tuning\nparam_grid = {'normalize': [True, False]}  # You can add more hyperparameters to tune\ngrid_search = GridSearchCV(baseline_model, param_grid, cv=3)\ngrid_search.fit(X_train, y_train)\n\n# Get the best Linear Regression model with the best parameters\nbest_model_1 = grid_search.best_estimator_\n\n# Fit the best model on the training data\nbest_model_1.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred_1 = best_model_1.predict(X_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:31:01.235366Z","iopub.execute_input":"2023-08-29T16:31:01.235812Z","iopub.status.idle":"2023-08-29T16:31:01.286642Z","shell.execute_reply.started":"2023-08-29T16:31:01.235766Z","shell.execute_reply":"2023-08-29T16:31:01.285600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2.DecisionTree Regression Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Create a Decision Tree Regressor\nbaseline_model = DecisionTreeRegressor()\n\n# Hyperparameter tuning\nparam_grid = {'max_depth': [None, 5, 10, 20],\n              'min_samples_split': [2, 5, 10],\n              'min_samples_leaf': [1, 2, 4]}\ngrid_search = GridSearchCV(baseline_model, param_grid, cv=3)\ngrid_search.fit(X_train, y_train)\n\n# Get the best Decision Tree Regressor model with the best parameters\nbest_model_2 = grid_search.best_estimator_\n\n# Fit the best model on the training data\nbest_model_2.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred_2 = best_model_2.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:31:01.287873Z","iopub.execute_input":"2023-08-29T16:31:01.288123Z","iopub.status.idle":"2023-08-29T16:31:01.784575Z","shell.execute_reply.started":"2023-08-29T16:31:01.288083Z","shell.execute_reply":"2023-08-29T16:31:01.783498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3. Random Forest regression  Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Create a Random Forest Regressor\nbaseline_model = RandomForestRegressor()\n\n# Hyperparameter tuning\nparam_grid = {'n_estimators': [100, 200, 300],\n              'max_depth': [None, 5, 10, 20],\n              'min_samples_split': [2, 5, 10],\n              'min_samples_leaf': [1, 2, 4]}\ngrid_search = GridSearchCV(baseline_model, param_grid, cv=3)\ngrid_search.fit(X_train, y_train)\n\n# Get the best Random Forest Regressor model with the best parameters\nbest_model_3 = grid_search.best_estimator_\n\n# Fit the best model on the training data\nbest_model_3.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred_3 = best_model.predict(X_test)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:31:01.785951Z","iopub.execute_input":"2023-08-29T16:31:01.786376Z","iopub.status.idle":"2023-08-29T16:32:08.329602Z","shell.execute_reply.started":"2023-08-29T16:31:01.786210Z","shell.execute_reply":"2023-08-29T16:32:08.328561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{"_uuid":"b0127acdc8615bb40259e313f1d91e263091ce5c"}},{"cell_type":"markdown","source":"To compare the performance of different regression models (Linear Regression, Decision Tree, Random Forest) and determine which one is best for your specific dataset, you can evaluate each model using appropriate metrics such as **Mean Squared Error (MSE)**, **Root Mean Squared Error (RMSE)**, **Mean Absolute Error (MAE)**, and **R-squared**. After evaluating each model, you can compare their performance metrics to decide which one performs the best.","metadata":{}},{"cell_type":"markdown","source":"**LinearRegression Model Evaluation**","metadata":{}},{"cell_type":"code","source":"# Calculate Mean Squared Error (MSE)\nmse = mean_squared_error(y_test, y_pred_1)\nprint(\"Mean Squared Error:\", mse)\n\n# Calculate Root Mean Squared Error (RMSE)\nrmse = np.sqrt(mse)\nprint(\"Root Mean Squared Error:\", rmse)\n\n# Calculate Mean Absolute Error (MAE)\nmae = mean_absolute_error(y_test, y_pred_1)\nprint(\"Mean Absolute Error:\", mae)\n\n# Calculate R-squared (Coefficient of Determination)\nr2 = r2_score(y_test, y_pred_1)\nprint(\"R-squared:\", r2)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:32:08.331556Z","iopub.execute_input":"2023-08-29T16:32:08.331837Z","iopub.status.idle":"2023-08-29T16:32:08.339938Z","shell.execute_reply.started":"2023-08-29T16:32:08.331789Z","shell.execute_reply":"2023-08-29T16:32:08.339180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DecisionTreeRegression Model Evaluation**","metadata":{}},{"cell_type":"code","source":"# Calculate Mean Squared Error (MSE)\nmse = mean_squared_error(y_test, y_pred_2)\nprint(\"Mean Squared Error:\", mse)\n\n# Calculate Root Mean Squared Error (RMSE)\nrmse = np.sqrt(mse)\nprint(\"Root Mean Squared Error:\", rmse)\n\n# Calculate Mean Absolute Error (MAE)\nmae = mean_absolute_error(y_test, y_pred_2)\nprint(\"Mean Absolute Error:\", mae)\n\n# Calculate R-squared (Coefficient of Determination)\nr2 = r2_score(y_test, y_pred_2)\nprint(\"R-squared:\", r2)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:32:08.341541Z","iopub.execute_input":"2023-08-29T16:32:08.341831Z","iopub.status.idle":"2023-08-29T16:32:08.357693Z","shell.execute_reply.started":"2023-08-29T16:32:08.341783Z","shell.execute_reply":"2023-08-29T16:32:08.356680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RandomForestRegression Model Evaluation**","metadata":{}},{"cell_type":"code","source":"# Calculate Mean Squared Error (MSE)\nmse = mean_squared_error(y_test, y_pred_3)\nprint(\"Mean Squared Error:\", mse)\n\n# Calculate Root Mean Squared Error (RMSE)\nrmse = np.sqrt(mse)\nprint(\"Root Mean Squared Error:\", rmse)\n\n# Calculate Mean Absolute Error (MAE)\nmae = mean_absolute_error(y_test, y_pred_3)\nprint(\"Mean Absolute Error:\", mae)\n\n# Calculate R-squared (Coefficient of Determination)\nr2 = r2_score(y_test, y_pred_3)\nprint(\"R-squared:\", r2)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T16:32:08.359007Z","iopub.execute_input":"2023-08-29T16:32:08.359259Z","iopub.status.idle":"2023-08-29T16:32:08.375989Z","shell.execute_reply.started":"2023-08-29T16:32:08.359212Z","shell.execute_reply":"2023-08-29T16:32:08.374461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Comparison\n\n| Model                | RMSE                | MAE                 |     R-squared       |\n|----------------------|---------------------|---------------------|---------------------|\n| Linear Regression    | 1.6235998775338913  | 1.2278183566589418  | 0.8655979373420271  |\n| Decision Tree        | 1.6269261194734022  | 1.3483167989417992  | 0.8650466787227526  |\n| Random Forest        | 1.1670994173591218  | 0.9642500000000004  | 0.9305513802876184  |\n\n### Summary\n\nBased on the evaluation metrics, the Random Forest model outperforms the other models in terms of RMSE, MAE, and R-squared. It achieved the lowest RMSE and MAE values, indicating better predictive accuracy. The high R-squared value suggests that a significant portion of the variance in the target variable is explained by the model. While the Decision Tree model also performed well, the Random Forest model demonstrates superior performance and generalization capability.\n\nThe Random Forest model is recommended for this project due to its strong predictive performance and ability to handle complex relationships within the data.\n","metadata":{}}]}